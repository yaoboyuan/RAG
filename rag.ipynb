{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a548959-993c-43e4-b617-4d1c9be6aa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import bs4\n",
    "import sys\n",
    "import time\n",
    "import tiktoken\n",
    "import warnings\n",
    "from tqdm.auto import tqdm, trange\n",
    "from langchain import hub\n",
    "from langchain.load import dumps, loads\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_community.document_loaders import PyMuPDFLoader, UnstructuredExcelLoader, UnstructuredCSVLoader, WebBaseLoader\n",
    "\n",
    "work_directory = '/home/boyuan/RAG'\n",
    "model_path = '/home/boyuan/Llama-2-7b-chat-hf/Llama-2-7b-chat-hf.gguf'\n",
    "embedding_model = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "embedding_device = 'cpu'\n",
    "docs_path = '/home/boyuan/RAG/sae_story.pdf'\n",
    "db_name = 'db_sae_story'\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c940765f-5053-49ac-8a7c-b7cf08c5de41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class RAG:\n",
    "    def __init__(self, model_path, docs_path, embedding_model, embedding_device, db_name):\n",
    "        self.llm = LlamaCpp(model_path=model_path, n_gpu_layers=100, n_batch=512, n_ctx=2048, f16_kv=True,\n",
    "                            callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]), verbose=False)\n",
    "        embedding = HuggingFaceEmbeddings(model_name=embedding_model, model_kwargs={'device': embedding_device})\n",
    "        docs = self.__docs_loader(docs_path)\n",
    "        splits = self.__spliter(docs)\n",
    "        vectorstore = Chroma.from_documents(documents=splits, embedding=embedding, persist_directory=db_name)\n",
    "        retriever = vectorstore.as_retriever(search_type='similarity', search_kwargs={'k': 1})\n",
    "        template = \"\"\"Answer the question based only on the following context:{context}\n",
    "        Question: {question}\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        self.chain = (\n",
    "            {'context': retriever, 'question': RunnablePassthrough()}\n",
    "            | prompt\n",
    "            | self.llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        \n",
    "    def convert_tokens(self, s, encoding_name='cl100k_base'):\n",
    "        encoding = tiktoken.get_encoding(encoding_name)\n",
    "        res = encoding.encode(s)\n",
    "        return res\n",
    "        \n",
    "    def __docs_loader(self, path):\n",
    "        if os.path.isfile(path):\n",
    "            file_name = os.path.basename(path)\n",
    "            extension = file_name.split('.')[1]\n",
    "            if extension == 'pdf':\n",
    "                loader = PyMuPDFLoader(path)\n",
    "                res = loader.load()\n",
    "            elif extension == 'xlsx':\n",
    "                loader = UnstructuredExcelLoader(path, mode=\"elements\")\n",
    "                res = loader.load()\n",
    "            elif extension == 'csv':\n",
    "                loader = UnstructuredCSVLoader(path, mode=\"elements\")\n",
    "                res = loader.load()\n",
    "            else:\n",
    "                raise Exception('Error: Not pdf file.')\n",
    "        elif path.startswith('http') or path.startswith('https'):\n",
    "            bs4_strainer = bs4.SoupStrainer(class_=('post-content', 'post-title', 'post-header')) # Only keep post title, headers, and content\n",
    "            loader = WebBaseLoader(web_paths=(path,), bs_kwargs={\"parse_only\": bs4_strainer})\n",
    "            res = loader.load()\n",
    "        else:\n",
    "            print('Error: Not pdf or website start with http or https')\n",
    "        return res\n",
    "\n",
    "    def __spliter(self, docs):\n",
    "        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(encoding_name='cl100k_base', chunk_size=20, chunk_overlap=0)\n",
    "        splits = text_splitter.split_documents(docs)\n",
    "        if 'languages' in splits[0].metadata and type(splits[0].metadata['languages'] == list):\n",
    "            for s in splits:\n",
    "                s.metadata['languages'] = s.metadata['languages'][0]\n",
    "        return splits\n",
    "        \n",
    "rag = RAG(model_path, docs_path, embedding_model, embedding_device, db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "435d7cf3-f133-468a-8ea9-8c39883f3a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: Based on the context provided, there is no information available about a person named Andy in the document."
     ]
    }
   ],
   "source": [
    "ans = rag.chain.invoke('Tell me about Andy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
